Using TensorFlow backend.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Loading data...
1240 train sequences
138 validation sequences
154 evaluation sequences
embedding_lmdb_path is not specified in the embeddings registry, so the embeddings will be loaded in memory...
loading embeddings...
path: /lustre/group/tdm/Luca/delft/delft/data/embeddings/glove.840B.300d.txt
embeddings loaded for 2196017 words and 300 dimensions

Evaluation:

------------------------ fold 0 --------------------------------------
	f1 (micro): 89.26
                  precision    recall  f1-score   support

      <unitLeft>     0.9472    0.9729    0.9598       258
     <unitRight>     1.0000    0.9091    0.9524        11
   <valueAtomic>     0.8379    0.9013    0.8685       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8659    0.8875    0.8765        80
     <valueList>     0.7313    0.8167    0.7717        60
     <valueMost>     0.9254    0.8052    0.8611        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8786    0.9069    0.8926       806


------------------------ fold 1 --------------------------------------
	f1 (micro): 89.12
                  precision    recall  f1-score   support

      <unitLeft>     0.9470    0.9690    0.9579       258
     <unitRight>     0.8333    0.9091    0.8696        11
   <valueAtomic>     0.8405    0.9013    0.8698       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.9041    0.8250    0.8627        80
     <valueList>     0.7385    0.8000    0.7680        60
     <valueMost>     0.8816    0.8701    0.8758        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8783    0.9045    0.8912       806


------------------------ fold 2 --------------------------------------
	f1 (micro): 86.39
                  precision    recall  f1-score   support

      <unitLeft>     0.9688    0.9612    0.9650       258
     <unitRight>     0.8182    0.8182    0.8182        11
   <valueAtomic>     0.7976    0.8684    0.8315       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8857    0.7750    0.8267        80
     <valueList>     0.7347    0.6000    0.6606        60
     <valueMost>     0.8611    0.8052    0.8322        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8655    0.8623    0.8639       806


------------------------ fold 3 --------------------------------------
	f1 (micro): 88.66
                  precision    recall  f1-score   support

      <unitLeft>     0.9617    0.9729    0.9672       258
     <unitRight>     0.9000    0.8182    0.8571        11
   <valueAtomic>     0.8344    0.8783    0.8558       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8904    0.8125    0.8497        80
     <valueList>     0.7246    0.8333    0.7752        60
     <valueMost>     0.9130    0.8182    0.8630        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8811    0.8921    0.8866       806


------------------------ fold 4 --------------------------------------
	f1 (micro): 86.92
                  precision    recall  f1-score   support

      <unitLeft>     0.9502    0.9612    0.9557       258
     <unitRight>     0.9000    0.8182    0.8571        11
   <valueAtomic>     0.8140    0.8783    0.8449       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8571    0.8250    0.8408        80
     <valueList>     0.7097    0.7333    0.7213        60
     <valueMost>     0.8493    0.8052    0.8267        77
    <valueRange>     1.0000    0.7500    0.8571         8

all (micro avg.)     0.8603    0.8784    0.8692       806


------------------------ fold 5 --------------------------------------
	f1 (micro): 86.62
                  precision    recall  f1-score   support

      <unitLeft>     0.9251    0.9574    0.9410       258
     <unitRight>     0.9000    0.8182    0.8571        11
   <valueAtomic>     0.7906    0.8816    0.8336       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.9155    0.8125    0.8609        80
     <valueList>     0.7458    0.7333    0.7395        60
     <valueMost>     0.8732    0.8052    0.8378        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8532    0.8797    0.8662       806


------------------------ fold 6 --------------------------------------
	f1 (micro): 88.49
                  precision    recall  f1-score   support

      <unitLeft>     0.9506    0.9690    0.9597       258
     <unitRight>     0.9000    0.8182    0.8571        11
   <valueAtomic>     0.8267    0.8947    0.8594       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8919    0.8250    0.8571        80
     <valueList>     0.7759    0.7500    0.7627        60
     <valueMost>     0.8873    0.8182    0.8514        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8779    0.8921    0.8849       806


------------------------ fold 7 --------------------------------------
	f1 (micro): 88.51
                  precision    recall  f1-score   support

      <unitLeft>     0.9577    0.9651    0.9614       258
     <unitRight>     1.0000    0.8182    0.9000        11
   <valueAtomic>     0.8263    0.9079    0.8652       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8919    0.8250    0.8571        80
     <valueList>     0.7302    0.7667    0.7480        60
     <valueMost>     0.8971    0.7922    0.8414        77
    <valueRange>     1.0000    0.8750    0.9333         8

all (micro avg.)     0.8770    0.8933    0.8851       806


------------------------ fold 8 --------------------------------------
	f1 (micro): 88.18
                  precision    recall  f1-score   support

      <unitLeft>     0.9577    0.9651    0.9614       258
     <unitRight>     1.0000    0.8182    0.9000        11
   <valueAtomic>     0.8006    0.8980    0.8465       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.9265    0.7875    0.8514        80
     <valueList>     0.8148    0.7333    0.7719        60
     <valueMost>     0.8889    0.8312    0.8591        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8753    0.8883    0.8818       806


------------------------ fold 9 --------------------------------------
	f1 (micro): 88.88
                  precision    recall  f1-score   support

      <unitLeft>     0.9508    0.9729    0.9617       258
     <unitRight>     1.0000    0.8182    0.9000        11
   <valueAtomic>     0.8052    0.9112    0.8549       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8947    0.8500    0.8718        80
     <valueList>     0.8214    0.7667    0.7931        60
     <valueMost>     0.9254    0.8052    0.8611        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8759    0.9020    0.8888       806

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

      <unitLeft>     0.9688    0.9612    0.9650       258
     <unitRight>     0.8182    0.8182    0.8182        11
   <valueAtomic>     0.7976    0.8684    0.8315       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8857    0.7750    0.8267        80
     <valueList>     0.7347    0.6000    0.6606        60
     <valueMost>     0.8611    0.8052    0.8322        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8655    0.8623    0.8639       806


** Best ** model scores - run 0
                  precision    recall  f1-score   support

      <unitLeft>     0.9472    0.9729    0.9598       258
     <unitRight>     1.0000    0.9091    0.9524        11
   <valueAtomic>     0.8379    0.9013    0.8685       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8659    0.8875    0.8765        80
     <valueList>     0.7313    0.8167    0.7717        60
     <valueMost>     0.9254    0.8052    0.8611        77
    <valueRange>     1.0000    1.0000    1.0000         8

all (micro avg.)     0.8786    0.9069    0.8926       806

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

      <unitLeft>     0.9517    0.9667    0.9591       258
     <unitRight>     0.9252    0.8364    0.8769        11
   <valueAtomic>     0.8174    0.8921    0.8530       304
     <valueBase>     1.0000    0.7500    0.8571         8
    <valueLeast>     0.8924    0.8225    0.8555        80
     <valueList>     0.7527    0.7533    0.7512        60
     <valueMost>     0.8902    0.8156    0.8510        77
    <valueRange>     1.0000    0.9625    0.9790         8

all (micro avg.)     0.8723    0.8900    0.8810          

model config file saved
preprocessor saved
model saved
