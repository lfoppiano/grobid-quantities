Using TensorFlow backend.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Loading data...
3928 train sequences
437 validation sequences
486 evaluation sequences
embedding_lmdb_path is not specified in the embeddings registry, so the embeddings will be loaded in memory...
loading embeddings...
path: /lustre/group/tdm/Luca/delft/delft/data/embeddings/glove.840B.300d.txt
embeddings loaded for 2196017 words and 300 dimensions

Evaluation:

------------------------ fold 0 --------------------------------------
	f1 (micro): 98.38
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9950    0.9826    0.9888       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.7619    1.0000    0.8649        16

all (micro avg.)     0.9838    0.9838    0.9838       494


------------------------ fold 1 --------------------------------------
	f1 (micro): 97.87
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     0.7500    0.7500    0.7500         4
        <number>     0.9975    0.9801    0.9887       403
           <pow>     0.6667    0.5000    0.5714         4
          <time>     0.6957    1.0000    0.8205        16

all (micro avg.)     0.9797    0.9777    0.9787       494


------------------------ fold 2 --------------------------------------
	f1 (micro): 97.17
                  precision    recall  f1-score   support

         <alpha>     0.9851    0.9851    0.9851        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9949    0.9727    0.9837       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.5926    1.0000    0.7442        16

all (micro avg.)     0.9698    0.9737    0.9717       494


------------------------ fold 3 --------------------------------------
	f1 (micro): 97.77
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9752    0.9862       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.6400    1.0000    0.7805        16

all (micro avg.)     0.9777    0.9777    0.9777       494


------------------------ fold 4 --------------------------------------
	f1 (micro): 99.19
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9950    0.9926    0.9938       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.9412    1.0000    0.9697        16

all (micro avg.)     0.9919    0.9919    0.9919       494


------------------------ fold 5 --------------------------------------
	f1 (micro): 98.07
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     0.7500    0.7500    0.7500         4
        <number>     0.9975    0.9826    0.9900       403
           <pow>     0.6667    0.5000    0.5714         4
          <time>     0.7273    1.0000    0.8421        16

all (micro avg.)     0.9817    0.9798    0.9807       494


------------------------ fold 6 --------------------------------------
	f1 (micro): 98.79
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9876    0.9925       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8000    1.0000    0.8889        16

all (micro avg.)     0.9879    0.9879    0.9879       494


------------------------ fold 7 --------------------------------------
	f1 (micro): 97.67
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     0.7500    0.7500    0.7500         4
        <number>     0.9975    0.9777    0.9875       403
           <pow>     0.6667    0.5000    0.5714         4
          <time>     0.6667    1.0000    0.8000        16

all (micro avg.)     0.9777    0.9757    0.9767       494


------------------------ fold 8 --------------------------------------
	f1 (micro): 98.79
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9876    0.9925       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8000    1.0000    0.8889        16

all (micro avg.)     0.9879    0.9879    0.9879       494


------------------------ fold 9 --------------------------------------
	f1 (micro): 97.87
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     0.7500    0.7500    0.7500         4
        <number>     0.9975    0.9801    0.9887       403
           <pow>     0.6667    0.5000    0.5714         4
          <time>     0.6957    1.0000    0.8205        16

all (micro avg.)     0.9797    0.9777    0.9787       494

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

         <alpha>     0.9851    0.9851    0.9851        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9949    0.9727    0.9837       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.5926    1.0000    0.7442        16

all (micro avg.)     0.9698    0.9737    0.9717       494


** Best ** model scores - run 4
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9950    0.9926    0.9938       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.9412    1.0000    0.9697        16

all (micro avg.)     0.9919    0.9919    0.9919       494

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

         <alpha>     0.9985    0.9985    0.9985        67
          <base>     0.9000    0.9000    0.9000         4
        <number>     0.9967    0.9819    0.9892       403
           <pow>     0.7167    0.6500    0.6786         4
          <time>     0.7321    1.0000    0.8420        16

all (micro avg.)     0.9818    0.9814    0.9816          

model config file saved
preprocessor saved
model saved
