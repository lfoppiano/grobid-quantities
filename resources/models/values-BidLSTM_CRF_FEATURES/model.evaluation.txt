Using TensorFlow backend.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Loading data...
3928 train sequences
437 validation sequences
486 evaluation sequences
embedding_lmdb_path is not specified in the embeddings registry, so the embeddings will be loaded in memory...
loading embeddings...
path: /lustre/group/tdm/Luca/delft/delft/data/embeddings/glove.840B.300d.txt
embeddings loaded for 2196017 words and 300 dimensions

Evaluation:

------------------------ fold 0 --------------------------------------
	f1 (micro): 98.08
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9875    0.9826    0.9851       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.7619    1.0000    0.8649        16

all (micro avg.)     0.9779    0.9838    0.9808       494


------------------------ fold 1 --------------------------------------
	f1 (micro): 99.19
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9926    0.9950       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8889    1.0000    0.9412        16

all (micro avg.)     0.9919    0.9919    0.9919       494


------------------------ fold 2 --------------------------------------
	f1 (micro): 98.08
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9925    0.9801    0.9863       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.7273    1.0000    0.8421        16

all (micro avg.)     0.9798    0.9818    0.9808       494


------------------------ fold 3 --------------------------------------
	f1 (micro): 97.98
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     0.6667    1.0000    0.8000         4
        <number>     0.9975    0.9801    0.9887       403
           <pow>     0.5000    0.7500    0.6000         4
          <time>     0.7619    1.0000    0.8649        16

all (micro avg.)     0.9778    0.9818    0.9798       494


------------------------ fold 4 --------------------------------------
	f1 (micro): 98.99
                  precision    recall  f1-score   support

         <alpha>     0.9851    0.9851    0.9851        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9926    0.9950       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8889    1.0000    0.9412        16

all (micro avg.)     0.9899    0.9899    0.9899       494


------------------------ fold 5 --------------------------------------
	f1 (micro): 98.18
                  precision    recall  f1-score   support

         <alpha>     0.9559    0.9701    0.9630        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9950    0.9876    0.9913       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8000    1.0000    0.8889        16

all (micro avg.)     0.9798    0.9838    0.9818       494


------------------------ fold 6 --------------------------------------
	f1 (micro): 98.89
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9950    0.9901    0.9925       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8421    1.0000    0.9143        16

all (micro avg.)     0.9879    0.9899    0.9889       494


------------------------ fold 7 --------------------------------------
	f1 (micro): 98.58
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9851    0.9913       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.7619    1.0000    0.8649        16

all (micro avg.)     0.9858    0.9858    0.9858       494


------------------------ fold 8 --------------------------------------
	f1 (micro): 98.58
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9851    0.9913       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.7619    1.0000    0.8649        16

all (micro avg.)     0.9858    0.9858    0.9858       494


------------------------ fold 9 --------------------------------------
	f1 (micro): 99.19
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9926    0.9950       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8889    1.0000    0.9412        16

all (micro avg.)     0.9919    0.9919    0.9919       494

----------------------------------------------------------------------

** Worst ** model scores - run 3
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     0.6667    1.0000    0.8000         4
        <number>     0.9975    0.9801    0.9887       403
           <pow>     0.5000    0.7500    0.6000         4
          <time>     0.7619    1.0000    0.8649        16

all (micro avg.)     0.9778    0.9818    0.9798       494


** Best ** model scores - run 1
                  precision    recall  f1-score   support

         <alpha>     1.0000    1.0000    1.0000        67
          <base>     1.0000    1.0000    1.0000         4
        <number>     0.9975    0.9926    0.9950       403
           <pow>     0.7500    0.7500    0.7500         4
          <time>     0.8889    1.0000    0.9412        16

all (micro avg.)     0.9919    0.9919    0.9919       494

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

         <alpha>     0.9941    0.9955    0.9948        67
          <base>     0.9667    1.0000    0.9800         4
        <number>     0.9955    0.9868    0.9911       403
           <pow>     0.7250    0.7500    0.7350         4
          <time>     0.8084    1.0000    0.8928        16

all (micro avg.)     0.9849    0.9866    0.9857          

model config file saved
preprocessor saved
model saved
