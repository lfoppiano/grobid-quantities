<tei xmlns="http://www.tei-c.org/ns/1.0">
	<teiHeader>
		<fileDesc xml:id="_1" />
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-08-22T14:32+0000">
					<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
	</teiHeader>
	<text xml:lang="en">
		<p>An allergy is an abnormal reaction of the immune system towards foreign substances (allergens) that are normally harmless. Peanut allergies in particular affect more than <measure type="interval"><num atLeast="0.5">0.5</num><measure type="FRACTION" unit="%">%</measure></measure> of the entire French population, and its increasing prevalence and potentially severe clinical reactions make it a public health problem. It is also the most lethal food allergy [4]. Following a strict avoidance diet is currently the only effective treatment that minimises potentially lethal accidents.</p>
		<p>Diagnosing and scoring peanut allergies is currently performed with a double blind placebo controlled food challenge (DBPCFC) <!--[3]-->. Patients are given increasing peanut doses until the first clinical reaction appears. Those showing specific allergy symptoms are declared allergic, and a particular avoidance treatment is then initiated. DBPCFC is also used to judge the severity of an established peanut allergy by determining the cumulative dose that triggers the first reaction, known as the eliciting dose [in milligrams (mg)]. However, these tests require patient hospitalisation in specialised centers and can potentially result in life-threatening reactions from patients with severe allergies. The DBPCFC is also a costly and time consuming test to conduct. The severity of peanut allergies is usually scored using the following scale <!--[1]--> :</p>
		<p>• Score 1: Mild symptoms among : abdominal pains that spontaneously resolve under <measure type="interval"><num atMost="30">30</num> <measure type="TIME" unit="min">minutes</measure></measure> and/or rhinocunjunctivitis and/or urticaria &lt; <measure type="interval"><num atMost="100">10</num></measure> papulas and/or a rash (eczema onset);</p>
		<p>• Score 2: <measure type="value"><num>One</num></measure> moderate symptom among : abdominal pain requiring treatment or generalized urticaria or non-laryngeal angioedema or cough or fall of Peak Expiratory Flow between <measure type="interval"><num atLeast="15">15</num> and <num atMost="20">20</num><measure type="FRACTION" unit="%">%</measure></measure>;</p>
		<p>• Score 3: <measure type="value"><num>Two</num></measure> moderate symptoms in the preceding list;</p>
		<p>• Score 4: <measure type="value"><num>Three</num></measure> moderate symptoms in the preceding list or laryngeal oedema or hypotension or asthma requiring treatment;</p>
		<p>• Score 5: Any symptom requiring hospitalisation in intensive care.</p>
		<p>For an already diagnosed allergy, it would be much more advantageous to predict the severity of the reaction from accidental exposure by using a blood sample or cutaneous test. This would replace the DBPCFC test with a simple statistical tool that can still evaluate potential risk without exposing the patient to a life-threatening allergic situation. Such a diagnostic method would be a major advance in food allergies and be beneficial to both patients and clinicians. The first objective of this paper was to select a set of discriminant variables which can offer useful information about the severity of peanut allergy. These variables could provide biologists and allergists a better understanding of the mechanisms inducing allergic reactions. Moreover this will allow to avoid measuring useless variables in further studies.</p>
		<p>The second goal of this study was to predict the DBPCFC score, the eliciting dose and the first accidental exposure score, evaluated a posteriori with the patient's medical record according to the same scale as the DBPCFC score. The first accidental exposure score would then reveal the "real" severity of the allergy. Compare this to using the DBPCFC, which only offers a minimal view of the severity since the procedure is terminated once the first symptoms appear.</p>
		<p>A clinical study was performed using <measure type="value"><num>76</num></measure> allergic patients with ages from <measure type="interval"><num atLeast="3">3</num> to <num atMost="18">18</num> <measure type="TIME" unit="year">years</measure></measure>. Tables 1 and 2 describe the frequencies observed for DBPCFC score, the first accidental exposure score and the eliciting dose. Note that only <measure type="value"><num>47 out of the 76</num></measure> patients experienced a first accident. The remaining <measure type="value"><num>29</num></measure> patients were diagnosed during an allergy check-up and subsequently confirmed by DBPCFC, thus avoiding further accidents. Patients were homogeneously distributed in age and sex across severity scores. <measure type="value"><num>Thirty-four</num></measure> variables were measured to reveal the presence of Immunoglobulins of type E (IgE) antibodies. These are proteins produced by the immune system that can elicit allergic reactions <!--[20]-->. Each antibody is specific to an allergen, i.e., it is coded to identify a particular protein for elimination. We measured the levels of IgE for the proteins of interest with the goal of building a predictive model of allergy severity. The variables used to test for IgE were measured either by immunoassays or by Skin Prick Tests (SPTs).</p>
		<p>Immunoassays are biochemical tests that quantify the level of antibodies in a blood sample (in kilo-units per liter ). We performed <measure type="value"><num>six</num></measure> immunoassays aimed at measuring the following: the total IgE, the specific IgE to peanut (f13), and the specific IgE to recombinant (r)Ara-h1, rAra-h2, rAra-h3, rAra-h8, which are IgE especially directed against peanut recombinant major allergens <!--[1]-->.</p>
		<p>SPTs are used to detect an immunological sensitivity to a particular substance. They show the functional aspect of cellular IgE, which are linked to mast cells releasing chemical mediators that elicit symptoms <!--[20]-->. A small dose of allergen is applied under the skin by pricking with a needle, and the diameter of the resulting wheal is measured in millimeters. We also measured the diameter of prick-tests to codeine as a positive control showing the basal reactivity of the skin. The ratio of the <measure type="value"><num>two</num></measure> diameters is used to measure the allergen reaction.</p>
		<p>We performed prick-tests for <measure type="value"><num>28</num></measure> allergens divided into <measure type="value"><num>three</num></measure> families:</p>
		<p>1. <measure type="value"><num>11</num></measure> nuts: almond, Brazil nut, cashew nut, chestnut, hazelnut, peanut, pecan nut, pine nut, pistachio, Queensland nut, walnut, which are often related to peanut allergies by cross-reactivity;</p><!--section 2 (2. 7 legumes: [...]) is missing-->
		<p>3. <measure type="value"><num>10</num></measure> aeroallergens: <measure type="value"><num>12</num></measure> grass pollens, Alternaria, ash, birch, cat epithelia, dog epithelia, Dpte (Dermatophago¨ıdesDermatophago¨ıdes pteronyssinus), mugwort, ribwort, rape seed, which are the common clinical allergens.</p>
		<p>Immunoassays and SPTs were measured immediately before DBPCFC.</p>
		<p>All computations were performed using the SAS Enterprise Guide 4.1.0.471 R or R 2.7.0 <!--[21]-->.</p>
		<p>We first performed a Principal Component Analysis (PCA) to gain an overview of the data.</p>
		<p>To solve our problems, discriminant analyses of DBPCFC score, first accident score and eliciting dose were performed by using several classifiers. <measure type="value"><num>Two</num></measure> studies were performed for each measure of severity by treating it as a <measure type="value"><num>four</num></measure>-class variable, and then as a <measure type="value"><num>two</num></measure>-class variable. For DBPCFC and first accidental exposure, <measure type="value"><num>4</num></measure> classes were built by considering the score groups {1}, {2}, {3} and {4, 5} because of the low frequency of score 5. For the <measure type="value"><num>two</num></measure>-class discrimination, groups were formed by scores of either {1, 2, 3} or {4, 5}, as recommended by clinicians. Since eliciting dose values are fixed by levels by the clinician <!--[1]-->, its measure is not a continuous variable and cannot be predicted by a regression analysis. Moreover although eliciting dose could be considered as a class variable, a discriminant analysis cannot be directly performed because of numerous categories with low frequencie (Table 2). A first solution consisted in converting eliciting dose into a <measure type="list"><num>four</num> or <num>two</num></measure>-class variable by searching the best discriminated classification computed with all available variables. A second solution will be proposed in Section 3.3. Careful variable selection appeared especially as a major point of the analysis. Therefore <measure type="value"><num>three</num></measure> different statistical approaches were proposed for each measure of severity :</p>
		<p>The performances of several classification rules were first compared without preselecting variables. Linear Discriminant Analysis (LDA), k-Nearest Neighbors (k−NN), Classification And Regression Trees (CART) <!--[10]--> and AdaBoost with CART <!--[5]--> were performed using all the <measure type="value"><num>34</num></measure> available variables as predictors. k−NN were performed for k ∈ {1,. .. , 5} and the number of nearest neighbors giving the best results was kept.</p>
		<p>Since in supervised learning keeping noisy predictors can increase the misclassification error, <measure type="value"><num>two</num></measure> methods that simulteanously perform variable selection and classification were also used : stepwise logistic regression <!--[11]--> and penalized SVM <!--[2]-->.</p>
		<p>As explained earlier, the determination of a set of predictors to keep is one of the main points of the study. Thus a variable selection scheme independent from classification was also developed. Variables were retained in the model if either the corresponding p-value of the Kruskal-Wallis test <!--[6]--> was smaller than <measure type="interval"><num atMost="0.10">0.10</num></measure>, or if the variable was selected by the stepwise Wilks' lambda (Λ) criterion <!--[13]-->. The Λ statistic was computed at each step with all variables already present in the model, whereas the F − to − enter statistic and corresponding p-value measure the discriminant power of a variable added to the preceding ones. For the latter, the maximal F − to − enter p-values used as entry and removal criteria were set by default to <measure type="value"><num>0.15</num></measure>, as recommended by [7]. The nonparametric Kruskal-Wallis test was preferred to ANOVA, because variables were not always normally distributed in the classes induced by the scores. Note that the Wilks' lambda selection is based on the hypotheses of multi-normality of the variables vector distribution and equality of the within-class covariance matrices. In <measure type="value"><num>1975</num></measure>, Lachenbruch <!--[14]--> asserted that the F −test is robust to small deviations of these hypotheses. We therefore decided to use the Wilks' lambda selection even though variables were not always normally distributed in the classes induced by the measures of severity. This variable selection scheme is a compromise between the assessment of variable marginal importance and the detection of a discriminant subset of predictors. This will allow first to provide biologists and allergists a list of informative variables in regards to the mechanisms involved in allergic reactions, and second to avoid keeping noisy variables that could degrade the performance of the learning algorithms. Biologists and allergists are particularly interested in using immunoassays as markers of the severity of peanut allergy because Specific IgE to rAra-h1, rAra-h2, rAra-h3 are yet known to be very useful in practice to detect peanut allergic patients <!--[1]-->. Moreover immunoassays are precise and reliable measures contrary to SPTs. But the number of discriminant SPTs can far exceed the number of selected immunoassays, which could possibly smear out the signal brought by immunoassays. As we wanted nevertheless to keep the information provided by SPTs, a Multiple Factorial Analysis (MFA) <!--[8]--> was performed to equalize the influence of both groups of selected variables, which enabled the use of factors as new predictors of severity. Thus we performed <measure type="value"><num>two</num></measure> discriminant analyses :</p>
		<p>1. by using directly the discriminant variables as predictors for classification with the methods introduced in Section 3.1.1, 2. by computing MFA factors of the discriminant variables and selecting a limited number of discriminant factors by the same selection process as the one used with raw variables, before performing the classification rules.</p>
		<p>The overall specific statistical approach is summarized in Figure 1. Figure 1: Specific statistical analysis for DBPCFC and first accident scores. The left path of the analysis gives a set of discriminant predictors without allowing for the weights of both groups of variables, whereas the right one uses equally-weighted groups of predictors.</p>
		<p>To discriminate this variable, we also devised an algorithm that simultaneously clusters the eliciting dose values and selects predictors by minimizing the Wilks' lambda (Section 3.3). This algorithm was applied by using raw variables or factors computed by MFA with the <measure type="value"><num>34</num></measure> available variables as predictors. Once the predictors were chosen and the clusters built, the same statistical approaches as for DBPCFC and first accident scores were used. The corresponding statistical analysis is summarized in Figure 2.</p>
		<p>MFA was introduced by B.Escofier and J.Pagès <!--[8,9]--> for sensory analysis, and is a PCA with a particular choice of metric. The aim of this method is to give a similar part to several groups of variables when determining factors, i.e., uncorrelated linear combinations of the initial variables. This procedure is useful for avoiding models that are fully influenced by a single group of numerous variables which could partially cancel the effect of the other groups. Briefly, an MFA is performed as follows : Suppose p variables are measured on n subjects and divided in q groups :</p>
		<p>with q k=<measure type="value"><num>1</num></measure> m k =p, where m k is the number of variables in group k. Denote X k the matrix of data of size n × p corresponding to the k th group of variables, namely :</p>
		<p>n where the generic element x k,j i denotes the measure of the variable x k,j for the sample point i. Let also X = (X 1 |. .. |X q ) be the matrix corresponding to the whole set of variables. For the k th group of variables, let M k be a metric matrix in R m k , k=<measure type="value"><num>1</num></measure>,. .. , q. Let D be the diagonal matrix of the weights assigned to the sample points. The MFA algorithm is then as follows :</p>
		<p>• Step 1 : For any 1 ≤ k ≤ q, perform PCA(X k ,M k ,D), and denote λ k 1 the greatest eigenvalue corresponding to the first factor ;</p>
		<p>• Step 2 : consider the metric matrix in R p :</p>
		<p>Note that in our case, q = <measure type="value"><num>2</num></measure> with the immunoassays as the first group of variables and the SPTs as the second. Variables were first centered and scaled to unity, and the metric matrix M k was then set to the identity matrix I k in R m k. For the DBPCFC and first accident scores, we thought it made more sense to compute the factors using only the discriminant variables rather than using all available variables. Indeed, the predictive model needed to be built with a reasonable number of characters. Even if a limited number of factors were chosen afterwards, all variables would still have to be measured to compute the factors. Moreover, a non-discriminant variable could have a large coefficient for some retained factors even though it would not improve the overall discriminative power of the model. Nonetheless, we did compute factors using all variables as well, but the results did not improve the discrimination of the first accident score. For the eliciting dose, factors were computed using all <measure type="value"><num>34</num></measure> available variables, not only the discriminant ones. As described in Section 3.3, the set of discriminant variables depends on the choice of the clustering of eliciting dose values and vice versa. Thus it did not seem appropriate to replace the optimal set of variables by factors.</p>
		<p>variable and selecting discriminant variables</p>
		<p>Eliciting dose is a variable whose values are taken according to an increasing scale of fixed doses of peanut. For a given patient, only an interval including the eliciting dose is actually known. We wished first to group eliciting dose values in a limited number of intervals, and second to select the most discriminant variables for these categories.</p>
		<p>Here we propose an algorithm to perform these <measure type="value"><num>two</num></measure> steps simultaneously using alternate optimization.</p>
		<p>For a given partition in intervals, a set of discriminant variables of fixed cardinal is selected using a certain optimality criterion. A new partition in intervals is then determined to optimize this criterion with the chosen variables, and so on. In order to not repeat this algorithm for different values of the cardinal, the number of variables to include could be increased one-by-one at each step of the procedure. The optimal set of variables could then be searched into all the possible subsets of variables of fixed cardinal corresponding to this step. To avoid heavy computations, variables were included forward in the model. At each step, a new variable was chosen according to the optimality criterion and added to the preceding variables.</p>
		<p>Since Wilks' lambda provides a non-empirical stopping rule by testing its significance, this approach was preferred over using within-class inertia computation as the optimality criterion. The p-value of F − to − enter was set to <measure type="value"><num>0.15</num></measure>.</p>
		<p>Let y be an ordinal categorial variable of levels {m 1 ,. .. , m l }, m 1 &lt; m 2 &lt;. .. &lt; m l. Suppose that we want to cluster the levels of y into a limited number r of intervals ]m i , m j ]. Only consecutive levels can be gathered. We build consecutive left-opened and right-closed intervals by selecting the upper bounds. Thus the number of possible clusterings is C r−1 l−1 .</p>
		<p>The algorithm for computing intervals and selecting discriminant variables is as follows:</p>
		<p>• Step 1 :</p>
		<p>1. choose the clustering C 1 of eliciting dose values that minimises Λ, computed using all <measure type="value"><num>34</num></measure> available predictors ;</p>
		<p>2. select the predictor v 1 that minimises Λ with the obtained clustering C 1 ;</p>
		<p>• Step 2 :</p>
		<p>1. choose the clustering C 2 of eliciting dose values that minimises Λ, computed using the previously selected predictor v 1 ;</p>
		<p>2. select the predictor v 2 such that the paired predictors (v 1 , v 2 ) minimise Λ with the new clustering C 2 ;</p>
		<p>• and so on. . .</p>
		<p>• procedure stops if either no left predictor can improve the discriminant power of the model, i.e., if F − to − enter p−value is greater than <measure type="interval"><num atLeast="0.15">0.15</num></measure> <!--[13]-->, or if every predictor is already entered.</p>
		<p>Note that the F −to−enter value is only computed when a new variable is entered into the model. This algorithm was used with both the variables and the MFA factors computed using all <measure type="value"><num>34</num></measure> available variables. Since new discriminant variables could have been chosen at each step of the algorithm, there was no default starting set of discriminant variables. Moreover, it did not seem appropriate to perform the MFA at the end of the algorithm, since the selected variables were specifically chosen to discriminate the found clusters.</p>
		<p>Linear discriminant analysis, k-NN, CART <!--[10]--> and stepwise logistic regression <!--[11]--> are classic methods. For <measure type="value"><num>two</num></measure>-class discrimination we also used the AdaBoost algorithm with CART <!--[5]--> and penalized SVM. Since these are still recently developed algorithms, we briefly summarize their concepts below.</p>
		<p>Let {(x i , y i ) 1≤i≤n } a dataset, where x i ∈ R p is the vector of predictors, and y i ∈ {<measure type="list"><num>0</num>, <num>1</num></measure>} is a binary response variable to discriminate. The principle of the AdaBoost algorithm is to re-weight observations that were misclassified by a base classifier (CART in our case). At each step of the procedure, a new classification tree is randomly built, inducing new misclassified sample points whose weights are updated before the following step starts. The method proceeds according to the following algorithm:</p>
		<p>• Step 1 : assign equal weigths to all sample points w [0] i =1/n, ∀i = 1,. .. , n ; • Step 2 : for m=<measure type="value"><num>1</num></measure><!--like "k=<measure type="value"><num>1</num></measure>,. .. , q."-->,. .. , M do :</p>
		<p>2. classify the data by resubstitution : determinê g [m] (x i ), i = 1,. .. , n ;</p>
		<p>3. compute the misclassification rate :</p>
		<p>where</p>
		<p>4. update the weights</p>
		<p>• Step 3 : build the aggregated classifier</p>
		<p>A novel observation x is classified by the majority votê f AdaBoost (x), where vote m is weighted by α [m] . In this study AdaBoost was performed for M = <measure type="list"><num>50</num>, <num>100</num> and <num>200</num></measure> on the training set and the parameter value giving the best result was kept.</p>
		<p>Let {(x i , y i ) 1≤i≤n } a training set, where x i ∈ R p is the vector of predictors, and y i ∈ {<measure type="list"><num>−1</num>, <num>1</num></measure>} is the class label. The Support Vector Machine (SVM) algorithm gives the hyperplane H that best splits both groups and that is defined by the equation</p>
		<p>where &lt; .,. &gt; is the usual dot product in R p , w =(w 1 ,.. .,w p ) are the coefficients of the hyperplane and b is the intercept. The coefficients are obtained by solving the convex optimization problem :</p>
		<p>where λ is a positive tuning parameter, [.] + = max(., 0) is the positive part and pen λ (w ) = λw 2 2 = λ p j=1 (w j ) 2. The class label of a novel observation x is then given by sign(f (x)).</p>
		<p>To select a limited number of variables, the term pen λ in (9) can be replaced by a penalization function being singular at the origin and having a continuous first-order derivative <!--[22]-->. <measure type="value"><num>Two</num></measure> functions were used in this study :</p>
		<p>• Smoothly Clipped Absolute Deviation (SCAD) : pen λ (w ) = p j=1 p λ (w j ) where</p>
		<p>where a &gt; <measure type="interval"><num atLeast="2">2</num></measure> is a tuning parameter. As suggested in [2], a is set by default to <measure type="value"><num>3.7</num></measure>.</p>
		<p>The optimal λ was chosen by the algorithm in the set {<measure type="value"><num>0.05</num></measure>, , ,. .. , <measure type="list"><num>0.10</num><num>0.15</num><num>0.95</num></measure>} for L 1 penalization and in {<measure type="list"><num>0.10</num>, <num>0.20</num></measure>,. .. , <measure type="value"><num>1</num></measure>} for SCAD penalization. For both penalizations, variables with coefficient |w j | lower than a given were considered useless and removed from the model. In the penalized SVM R package, is set to <measure type="value"><num>0.001</num></measure> <!--[22]-->.</p>
		<p>The PCA representation of the variables was relevant. As seen on the correlation circle of Figure 3, intra-family correlations between variables were rather high but inter-family correlations were quite low (with the notable exception of nuts and aeroallergens). Moreover, the total IgE and specific IgE to rAra-h8 did not seem closely related to the other immunoassays, an observation fully validated by clinicians. Indeed, as explained earlier, the level of total IgE is the global measure of this antibody subclass, whereas the specific IgE to rAra-h1, rAra-h2 and rAra-h3 are directed against peanut allergens alone. Also, rAra-h8 is a homologous protein to the birch pollen allergen Bet-v1, sharing about <measure type="value"><num>66</num><measure type="FRACTION" unit="%">%</measure></measure> of their amino acid sequences. Thus patients sensitive to both peanut and birch pollen could present high values of specific IgE to rAra-h8 without being allergic to peanuts. These results confirmed clinical observations. Also, the individual representation did not provide supplementary information (data not shown), and no particular interpretation was evident for the PCA axes.</p>
		<p>Here we show the results for the prediction of the first accidental exposure score, the DBPCFC score and the eliciting dose. Tables 3, 4 and 5 give the well-classification rates obtained by combining the classifiers with the <measure type="value"><num>3</num></measure> different statistical approaches :</p>
		<p>1. direct application of the classifiers, The percentage of detected patients with high severity was also computed. According to clinicians, failing to detect patients with severe allergies could indeed lead to inappropriate food intake by the patient. Results are given including the variable selection scheme and/or MFA in the crossvalidation. For the first and the third variable selection schemes, only the classifier giving the best performances among LDA, k−NN, CART and AdaBoost is displayed. For penalized SVM, the best result between L 1 ans SCAD penalizations was kept.</p>
		<p>The variables obtained with the selection process offering the bests results are also given and summarized in Figure 4 for each measure of severity .</p>
		<p><measure type="value"><num>Four</num></measure>-class study Recall that in what follows, we combined scores 4 and 5 because of the low frequency of score 5. Thus the <measure type="value"><num>four</num></measure> classes considered here are for scores of {1}, {2}, {3}, and {4, 5}. Well-classification rates obtained by fourth-fold cross-validation with each statistical approach are shown in Table 3. The percentage of patients of score 4 who were correctly classified in class 4 is also given. Note that direct application of the classifiers could not have been performed since the number of variables was greater than the size of the learning sets. 5−NN combined with our specific variable selection scheme was the most performant classifier with <measure type="value"><num>41</num><measure type="FRACTION" unit="%">%</measure></measure> of well-classified patients, since stepwise logistic regression and penalized SVM did not give better results. Nevertheless all these results remained poor. Replacing variables by factors did not give better results than direct use of the variables. On the whole dataset <measure type="value"><num>7</num></measure> variables had a Kruskal-Wallis p-value lower than <measure type="interval"><num atMost="0.10">0.10</num></measure> (peanut, walnut, chick pea, pecan nut, broad bean, green pea, cashew nut, ordered by increasing p-value, Table 6) and <measure type="value"><num>8</num></measure> were retained in the Wilks' lambda selection (chick pea, specific IgE to rAra-h8, green pea, rape seed, peanut, ribwort, total IgE, specific IgE to rAra-h1, Table 7). Thus <measure type="value"><num>12</num></measure> different variables were selected in total (<measure type="value"><num>3</num></measure> immunoassays and <measure type="value"><num>9</num></measure> SPTs). <measure type="value"><num>Two</num></measure>-class study The methodology used was the same as for the <measure type="value"><num>four</num></measure>-class study. The method which gave the best results for <measure type="value"><num>two</num></measure>-class discrimination was 1−NN with factors computed from discriminant variables as predictors (<measure type="value"><num>81</num><measure type="FRACTION" unit="%">%</measure></measure> of well-classified sample points) (Table 3). Of the score 4 patients, <measure type="value"><num>74</num><measure type="FRACTION" unit="%">%</measure></measure> were correctly classified. Contrary to the <measure type="value"><num>four</num></measure>-class study, the use of factors improved the classification rates compared to the direct use of variables since using selected variables with 1−NN gave <measure type="value"><num>79</num><measure type="FRACTION" unit="%">%</measure></measure> of well-classification rate. The other models yielded poor results. Processing the variable selection on the whole dataset gave interesting results. <measure type="value"><num>Eleven</num></measure> different variables were selected to build discriminant factors: peanut, walnut, specific IgE to rAra-h1, specific IgE to rAra-h3, pecan nut for Kruskal-Wallis and peanut, specific IgE to rAra-h1, lupine flour, specific IgE to rAra-h2, ribwort, Dpte, birch, dog epithelia for Wilks' lambda. These immunoassays, as well as SPTs to nuts and legumes, are variables expected by clinicians. This indicates that our selection process seems to detect "useful" variables. More surprisingly, a few SPTs to aeroallergens were also selected. Indeed, these variables are not known to cross-react with peanuts. Note that the discriminant factors will have to be computed these variables to use the best model for further classification.</p>
		<p>The statistical approach used to predict the DBPCFC score was the same as for the first accident score. <measure type="value"><num>Four</num></measure>-class study Scores of 4 and 5 were again grouped together due to the low frequency of score 5. Although applying CART without preselecting variables gave the best results with a <measure type="value"><num>38</num><measure type="FRACTION" unit="%">%</measure></measure> successful classification rate, the overall misclassification error remained high ( Table 4). Note that with the specific variable selection approach, MFA was not performed since only SPTs were entered in the model during cross-validation. Interestingly <measure type="value"><num>7</num></measure> variables were entered in the classification tree performed on the whole dataset : lupine flour, specific IgE to f13, lentil, total IgE, specific IgE to rAra-h3, <measure type="value"><num>12</num></measure> grass pollens, specific IgE to rAra-h8, in order of selection. This means that although all variables were available for building a model only a few were considered as useful by the CART algorithm. <measure type="value"><num>Two</num></measure>-class study DBPCFC scores can be gathered into <measure type="value"><num>two</num></measure> classes in the same manner as for the first accidental exposure score. Overall, using 3-NN classification with our variable selection scheme offered the best results, with <measure type="value"><num>66</num><measure type="FRACTION" unit="%">%</measure></measure> of successfully classified sample points and <measure type="value"><num>33</num><measure type="FRACTION" unit="%">%</measure></measure> of successfully classified severe patients (Table 4). Total IgE was the only immunoassay retained in the model during cross-validation. Thus, no factor was computed. Indeed, assigning the same weight to this single variable as to the other variables did not seem appropriate, because total IgE are not antibodies specifically involved in peanut allergies, but in all allergic reactions. On the whole dataset this resulted in selecting variables lupine flour for Kruskal-Wallis and almond, total IgE, lupine, broad bean, pine nut for Wilks' lambda.</p>
		<p>Before applying directly all the classifiers without selecting variables and performing stepwise logistic regression and penalized SVM, eliciting dose was first converted into a class variable. During cross-validation values were gathered into the partition of minimal Wilks' lambda computed with all available variables. These results were compared to those obtained with our algorithm that simultaneously selects discriminant variables and groups the eliciting dose values in an optimal partition (Section 3.3). This was performed for both <measure type="value"><num>four</num></measure>-class (r = <measure type="value"><num>4</num></measure>) and <measure type="value"><num>two</num></measure>-class (r = <measure type="value"><num>2</num></measure>) studies. The minimal number of sample points in each class was set to <measure type="value"><num>10</num></measure>, in order to have class frequencies large enough to perform cross-validation. Note that this process was included in cross-validation. <measure type="value"><num>Four</num></measure>-class study</p>
		<p>The eliciting dose was correctly predicted for <measure type="value"><num>39</num><measure type="FRACTION" unit="%">%</measure></measure> of the patients using our algorithm and CART with variables. Moreover, only <measure type="value"><num>52</num><measure type="FRACTION" unit="%">%</measure></measure> of the patients from the lowest eliciting doses group were correctly classified. Other approaches did not give better results (Table 5) . Table 8 The algorithm stopped at step 7 because no additional improvement resulted afterwards. The selected variables were hazelnut, birch, pistachio, cashew nut, green pea, total IgE, pine nut and the bounds were <measure type="list"><num>95</num>, <num>215</num>, and <num>500</num> <measure type="MASS" unit="mg">mg</measure></measure>. The same study was performed with factors as predictors but it did not enhance the model. <measure type="value"><num>Two</num></measure>-class study Selecting factors of all available variables with our algorithm was the most discriminant model to discriminate the eliciting dose in the <measure type="value"><num>two</num></measure>-class study (<measure type="value"><num>77</num><measure type="FRACTION" unit="%">%</measure></measure> were successfully classified with 5−NN). It also successfully classified <measure type="value"><num>72</num><measure type="FRACTION" unit="%">%</measure></measure> of the highly reactive patients. The threshold of eliciting dose was <measure type="value"><num>300</num> <measure type="MASS" unit="mg">mg</measure></measure> with <measure type="value"><num>7</num></measure> factors selected (Λ = <measure type="value"><num>0.62</num></measure>). Nevertheless, this model cannot easily be used in practice. Indeed, as mentioned earlier, MFA was performed on all <measure type="value"><num>34</num></measure> variables, not just the discriminant variables. This means that to correctly predict the eliciting dose, all variables would have to be measured to compute the factors; this does not seem feasible.</p>
		<p>To the best of our knowledge, this paper presents the first discriminant analysis of DBPCFC score, first accident score, and eliciting dose measurement of peanut allergy severity. Previous studies were aimed at finding links between immunoassays or SPTs and allergy severity, but their statistical analyses were limited to either comparing distributions between groups of patients (using, for instance, the Mann-Whitney test) or to computing linear correlation coefficients <!--[12,19]-->. In our approach, we used several classification rules to aid in comparing and choosing the optimal and most efficient method. It appeared that in general selecting discriminant variables by a process independent from classification gave better results. In addition, we found that using MFA to compute new predictors was an attractive solution when equalizing the weights of group variables, and we proposed a novel algorithm for simultaneously clustering the levels of ordinal qualitative variables and for selecting discriminant variables. Our work differs from earlier studies in several respects. Previous studies were performed on small sample sizes of <measure type="interval"><num atLeast="30">30</num> to <num atMost="40">40</num></measure> patients <!--[12,19]--> using a small number of measured variables, which only permitted a limited choice of discriminating predictors. Also, specific IgE to Ara-h1,2,3 were measured by SPTs instead of immunoassays <!--[19]--> and although a positive response to an SPT does indeed indicate allergen sensitivity, it is still less accurate than immunoassays. There are several scoring methods in the literature to evaluate peanut allergy severity. For example, Hourihane et al. devised a complex <measure type="value"><num>25</num></measure>-class scoring system combining observed reactions and eliciting doses <!--[12]-->. A graduation of symptoms was also proposed by Müller <!--[18]-->, but this score is based on allergic reactions in response to bee or wasp venom (and not peanut allergens). Thus, developing a standardized scoring method is still necessary and would facilitate comparison studies from different centers. One possible solution would be comparing the results of Hourihane et al.'s score with the one used in this study using the same cohort of patients. Moreover, the large number of scoring levels in Hourihane et al.'s approach could be reduced by our algorithm. Nevertheless, several potential biases in our study must be noted. First, SPT diameters are relatively imprecise. There is no standard method of measuring SPT reaction since both wheal diameters and areas are popular metrics <!--[19]-->. Additionally, the score of the first accident can be inaccurate or imprecise since it depends on the medical history of the patient, and hence subject to inaccuracies in the patient's memory which may underestimate symptom severity. Other factors such as medication can affect the first reaction symptoms as well <!--[15,17]--> yielding a severity score higher than it should be. Finally, the first exposure score is a past event predicted using variables measured during a subsequent DBPCFC. As mentioned in Section 4.2.2, Hourihane et al. also used such a reverse prediction with a community score that was evaluated a posteriori using the record file of the patient <!--[12]-->. The predictive models used in our study yielded correct classifications for the first accidental exposure and DBPCFC of up to <measure type="value"><num>81</num><measure type="FRACTION" unit="%">%</measure></measure> and <measure type="value"><num>66</num><measure type="FRACTION" unit="%">%</measure></measure> for the <measure type="value"><num>two</num></measure>-class study. Our algorithm also allowed us to group eliciting dose values and to select discriminant predictors, leading to an <measure type="value"><num>77</num><measure type="FRACTION" unit="%">%</measure></measure> classification rate for the <measure type="value"><num>two</num></measure>-class study. This indicates that it is indeed possible to correctly predict peanut allergy severity by measuring well-chosen variables. Considering that all immunoassays of specific IgE were selected once, we also hypothesize that measuring new antibodies to peanut allergens, such as those directed against rArah-6, rArah-7 and rArah-9, will further improve the discriminative power of our models. This also argues for these antibodies playing key roles in the diagnosis of peanut allergy severity. Our variable selection process also offers a new perspective on conducting allergy checkups. Indeed, some unexpected variables appeared several times in our models, such as SPTs to dog epithelia as shown in Figure 4. If future experiments could distinguish the medical relevance of this observation from cross-reactivity, then the importance of these SPTs in discriminating severity would be confirmed. Besides, some SPTs never appeared in our models, such as SPTs to Alternaria or Brazil nut, and thus should no longer be performed in practice when diagnosing peanut allergy severity. Furthermore, some SPTs with proven cross-reactivity to peanuts were retained in our models, such as lupine flour <!--[16]-->, indicating that our results were in line with other medical discoveries. The discriminating models described in this paper are a first step towards a simple, safe and efficient diagnosis of peanut allergy severity by quantifying antibodies. Before being applied in clinical practices, they must first be validated on an independent set of patients. New variables must also be added as additional predictors toward improving successful classification rates. These models could then become practical tools for clinicians. When scoring severity, the clinical test results could be reported online at the allergy vigilance network (Réseau d'allergovigilance, http://www.cicbaa.com/ ), or a simple statistical software could be programmed. Table 3: Results of the discriminant analysis of first accidental exposure score for the <measure type="value"><num>three</num></measure> kinds of variable selection schemes. The best classification method is given for the <measure type="value"><num>four</num></measure>-class and <measure type="value"><num>two</num></measure>-class studies. Results are expressed as successful classification rates and as severe patient detection rates. <!--method 4 classes 2 classes no selection x AdaBoost (M = <measure type="value"><num>50</num></measure>) : <measure type="interval"><num atLeast="63">63</num>%-<num atMost="33">33</num><measure type="FRACTION" unit="%">%</measure></measure> stepwise logistic regression <measure type="interval"><num atLeast="34">34</num>%-<num atMost="65% 63">65% 63</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="22.5">22.5</num><measure type="FRACTION" unit="%">%</measure> penalized SVM x L 1 : <num atLeast="61">61</num></measure>%-44% Kruskal-Wallis / Wilks' lambda with variables <measure type="value"><num>5</num><measure type="?" unit="NN">NN</measure></measure> : <measure type="value"><num>41</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="65">65</num><measure type="?" unit="% 1">% 1</measure>NN : <num atLeast="79">79</num></measure>%-72% Kruskal-Wallis / Wilks' lambda with factors <measure type="value"><num>1</num><measure type="?" unit="NN">NN</measure></measure> : <measure type="value"><num>34</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="46">46</num><measure type="?" unit="% 1">% 1</measure>NN : <num atLeast="81">81</num></measure>%-74% -->Table 4: Results of the discriminant analysis of DBPCFC score for the <measure type="value"><num>three</num></measure> kinds of variable selection schemes. The best classification method is given for the <measure type="value"><num>four</num></measure>-class and <measure type="value"><num>two</num></measure>-class studies. Results are expressed as successful classification rates and as severe patient detection rates. <!--method 4 classes 2 classes no selection CART : <measure type="interval"><num atLeast="38">38</num>%-<num atMost="44">44</num><measure type="?" unit="% 2">% 2</measure></measure>NN : <measure type="value"><num>64</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="37">37</num><measure type="FRACTION" unit="%">%</measure> stepwise logistic regression <num atLeast="35">35</num></measure>%-32% 56%-<measure type="interval"><num atMost="10">10</num><measure type="FRACTION" unit="%">%</measure> penalized SVM x L 1 : <num atLeast="62">62</num></measure>%-24% Kruskal-Wallis / Wilks' lambda with variables <measure type="value"><num>2</num><measure type="?" unit="NN">NN</measure></measure> : <measure type="value"><num>36</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="52">52</num><measure type="?" unit="% 3">% 3</measure>NN : <num atLeast="66">66</num></measure>%-33% Kruskal-Wallis / Wilks' lambda with factors x x -->Table 5: Results of the discriminant analysis of eliciting dose for the <measure type="value"><num>three</num></measure> kinds of variable selection schemes. The best classification method is given for the <measure type="value"><num>four</num></measure>-class and <measure type="value"><num>two</num></measure>-class studies. Results are expressed as successful classification rates and as severe patient detection rates. <!--method 4 classes 2 classes no selection LDA : <measure type="interval"><num atLeast="38">38</num>%-<num atMost="39">39</num><measure type="?" unit="% 5">% 5</measure></measure>NN : <measure type="interval"><num atLeast="69">69</num>%-<num atMost="62">62</num><measure type="FRACTION" unit="%">%</measure></measure> stepwise logistic regression <measure type="interval"><num atLeast="12">12</num>%-<num atMost="5% 58">5% 58</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="48">48</num><measure type="FRACTION" unit="%">%</measure> penalized SVM x L 1 : <num atLeast="66">66</num></measure>%-45% algorithm with variables CART : <measure type="value"><num>39</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="52">52</num><measure type="?" unit="% 1">% 1</measure>NN : <num atLeast="66">66</num></measure>%-36% algorithm with factors LDA : <measure type="value"><num>33</num><measure type="FRACTION" unit="%">%</measure></measure>-<measure type="interval"><num atMost="34">34</num><measure type="?" unit="% 5">% 5</measure>NN : <num atLeast="77">77</num></measure>%-72%--></p>
		<p>The authors would like to thank Frances T. Yen for her critical review of the manuscript.</p>
	</text>
</tei>